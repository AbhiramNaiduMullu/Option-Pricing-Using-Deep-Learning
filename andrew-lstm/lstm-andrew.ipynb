{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Activation, LeakyReLU, BatchNormalization, LSTM, Bidirectional, Input, Concatenate\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../options-df-sigma.csv')\n",
    "df = df.dropna(axis=0)\n",
    "df = df.drop(columns=['exdate', 'impl_volatility', 'volume', 'open_interest', 'sigma_20'])\n",
    "df.strike_price = df.strike_price / 1000\n",
    "call_df = df[df.cp_flag == 'C'].drop(['cp_flag'], axis=1)\n",
    "put_df = df[df.cp_flag == 'P'].drop(['cp_flag'], axis=1)\n",
    "underlying = pd.read_csv('../daily-closing-prices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19960102</td>\n",
       "      <td>620.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19960103</td>\n",
       "      <td>621.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19960104</td>\n",
       "      <td>617.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19960105</td>\n",
       "      <td>616.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19960108</td>\n",
       "      <td>618.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date   close\n",
       "0  19960102  620.73\n",
       "1  19960103  621.32\n",
       "2  19960104  617.70\n",
       "3  19960105  616.71\n",
       "4  19960108  618.46"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "underlying.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TIMESTEPS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padded = np.insert(underlying.close.values, 0, np.array([np.nan] * N_TIMESTEPS))\n",
    "# rolled = np.column_stack([np.roll(padded, i) for i in range(N_TIMESTEPS)])\n",
    "# rolled = rolled[~np.isnan(rolled).any(axis=1)]\n",
    "# rolled = np.column_stack((underlying.date.values[N_TIMESTEPS - 1:], rolled))\n",
    "# price_history = pd.DataFrame(data=rolled)\n",
    "# joined = df.join(price_history.set_index(0), on='date')\n",
    "# call_df = joined[joined.cp_flag == 'C'].drop(['cp_flag'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>strike_price</th>\n",
       "      <th>best_bid</th>\n",
       "      <th>best_offer</th>\n",
       "      <th>date_ndiff</th>\n",
       "      <th>treasury_rate</th>\n",
       "      <th>closing_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10751018</th>\n",
       "      <td>20171229</td>\n",
       "      <td>2950.0</td>\n",
       "      <td>25.10</td>\n",
       "      <td>26.5</td>\n",
       "      <td>367</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2673.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10751019</th>\n",
       "      <td>20171229</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>15.90</td>\n",
       "      <td>17.1</td>\n",
       "      <td>367</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2673.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10751020</th>\n",
       "      <td>20171229</td>\n",
       "      <td>3050.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.9</td>\n",
       "      <td>367</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2673.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10751021</th>\n",
       "      <td>20171229</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>6.40</td>\n",
       "      <td>7.1</td>\n",
       "      <td>367</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2673.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10751022</th>\n",
       "      <td>20171229</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>2.85</td>\n",
       "      <td>3.6</td>\n",
       "      <td>367</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2673.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  strike_price  best_bid  best_offer  date_ndiff  \\\n",
       "10751018  20171229        2950.0     25.10        26.5         367   \n",
       "10751019  20171229        3000.0     15.90        17.1         367   \n",
       "10751020  20171229        3050.0     10.00        10.9         367   \n",
       "10751021  20171229        3100.0      6.40         7.1         367   \n",
       "10751022  20171229        3200.0      2.85         3.6         367   \n",
       "\n",
       "          treasury_rate  closing_price  \n",
       "10751018           1.76        2673.61  \n",
       "10751019           1.76        2673.61  \n",
       "10751020           1.76        2673.61  \n",
       "10751021           1.76        2673.61  \n",
       "10751022           1.76        2673.61  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = np.insert(underlying.close.values, 0, np.array([np.nan] * N_TIMESTEPS))\n",
    "rolled = np.column_stack([np.roll(padded, i) for i in range(N_TIMESTEPS)])\n",
    "rolled = rolled[~np.isnan(rolled).any(axis=1)]\n",
    "rolled = np.column_stack((underlying.date.values[N_TIMESTEPS - 1:], rolled))\n",
    "price_history = pd.DataFrame(data=rolled)\n",
    "joined = df.join(price_history.set_index(0), on='date')\n",
    "call_df = joined[joined.cp_flag == 'C'].drop(['cp_flag'], axis=1)\n",
    "put_df = joined[joined.cp_flag == 'P'].drop(['cp_flag'], axis=1)\n",
    "call_df = call_df.drop(columns=['date'])\n",
    "put_df = put_df.drop(columns=['date'])\n",
    "call_X_train, call_X_test, call_y_train, call_y_test = train_test_split(call_df.drop(['best_bid', 'best_offer'], axis=1).values,\n",
    "                                                                        ((call_df.best_bid + call_df.best_offer) / 2).values,\n",
    "                                                                        test_size=0.01, random_state=42)\n",
    "put_X_train, put_X_test, put_y_train, put_y_test = train_test_split(put_df.drop(['best_bid', 'best_offer'], axis=1).values,\n",
    "                                                                    ((put_df.best_bid + put_df.best_offer) / 2).values,\n",
    "                                                                    test_size=0.01, random_state=42)\n",
    "call_X_train = [call_X_train[:, -N_TIMESTEPS:].reshape(call_X_train.shape[0], N_TIMESTEPS, 1), call_X_train[:, :4]]\n",
    "call_X_test = [call_X_test[:, -N_TIMESTEPS:].reshape(call_X_test.shape[0], N_TIMESTEPS, 1), call_X_test[:, :4]]\n",
    "put_X_train = [put_X_train[:, -N_TIMESTEPS:].reshape(put_X_train.shape[0], N_TIMESTEPS, 1), put_X_train[:, :4]]\n",
    "put_X_test = [put_X_test[:, -N_TIMESTEPS:].reshape(put_X_test.shape[0], N_TIMESTEPS, 1), put_X_test[:, :4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = 4\n",
    "n_timesteps = 60\n",
    "features = 4\n",
    "n_batch = 4096\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    close_history = Input((N_TIMESTEPS, 1))\n",
    "    input2 = Input((features,))\n",
    "    \n",
    "    lstm = Sequential()\n",
    "    lstm.add(LSTM(units=8, input_shape=(N_TIMESTEPS, 1), return_sequences=True))\n",
    "    lstm.add(LSTM(units=8, return_sequences=True))\n",
    "    lstm.add(LSTM(units=8, return_sequences=True))\n",
    "    lstm.add(LSTM(units=8, return_sequences=False))\n",
    "    input1 = lstm(close_history)\n",
    "    \n",
    "    connect = Concatenate()([input1, input2])\n",
    "    \n",
    "    for _ in range(layers - 1):\n",
    "        connect = Dense(100)(connect)\n",
    "        connect = BatchNormalization()(connect)\n",
    "        connect = LeakyReLU()(connect)\n",
    "    \n",
    "    predict = Dense(1, activation='relu')(connect)\n",
    "\n",
    "    return Model(inputs=[close_history, input2], outputs=predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "call_model = load_model('saved-models/20191207-call-lstm-v3.h5')\n",
    "put_model = make_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 20, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 8)            1952        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 12)           0           sequential_1[1][0]               \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          1300        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 100)          400         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 100)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          10100       leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 100)          400         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 100)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 100)          10100       leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 100)          400         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 100)          0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            101         leaky_re_lu_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 24,753\n",
      "Trainable params: 24,153\n",
      "Non-trainable params: 600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "call_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5001241 samples, validate on 50518 samples\n",
      "Epoch 1/10\n",
      "5001241/5001241 [==============================] - 217s 43us/step - loss: 104.1160 - val_loss: 4362.8883\n",
      "Epoch 2/10\n",
      "5001241/5001241 [==============================] - 211s 42us/step - loss: 107.9751 - val_loss: 334.2248\n",
      "Epoch 3/10\n",
      "5001241/5001241 [==============================] - 212s 42us/step - loss: 104.8956 - val_loss: 1896.3954\n",
      "Epoch 4/10\n",
      "5001241/5001241 [==============================] - 211s 42us/step - loss: 107.1401 - val_loss: 2703.8508\n",
      "Epoch 5/10\n",
      "5001241/5001241 [==============================] - 211s 42us/step - loss: 104.1657 - val_loss: 401.4244\n",
      "Epoch 6/10\n",
      "5001241/5001241 [==============================] - 210s 42us/step - loss: 101.9287 - val_loss: 328.0807\n",
      "Epoch 7/10\n",
      "5001241/5001241 [==============================] - 211s 42us/step - loss: 101.3158 - val_loss: 1531.7676\n",
      "Epoch 8/10\n",
      "5001241/5001241 [==============================] - 210s 42us/step - loss: 100.5739 - val_loss: 2019.2827\n",
      "Epoch 9/10\n",
      "5001241/5001241 [==============================] - 208s 42us/step - loss: 100.9698 - val_loss: 162.8337\n",
      "Epoch 10/10\n",
      "5001241/5001241 [==============================] - 209s 42us/step - loss: 106.8858 - val_loss: 797.5442\n"
     ]
    }
   ],
   "source": [
    "call_model.compile(optimizer=Adam(lr=1e-2), loss='mse')\n",
    "history = call_model.fit(call_X_train, call_y_train, \n",
    "                    batch_size=n_batch, epochs=10, \n",
    "                    validation_split = 0.01,\n",
    "                    callbacks=[TensorBoard()],\n",
    "                    verbose=1)\n",
    "call_model.save('saved-models/20191207-call-lstm-v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5001241 samples, validate on 50518 samples\n",
      "Epoch 1/5\n",
      "5001241/5001241 [==============================] - 217s 43us/step - loss: 86.7068 - val_loss: 64.7284\n",
      "Epoch 2/5\n",
      "5001241/5001241 [==============================] - 212s 42us/step - loss: 87.7861 - val_loss: 38.5577\n",
      "Epoch 3/5\n",
      "5001241/5001241 [==============================] - 212s 42us/step - loss: 80.6609 - val_loss: 67.4113\n",
      "Epoch 4/5\n",
      "5001241/5001241 [==============================] - 212s 42us/step - loss: 86.6304 - val_loss: 69.5275\n",
      "Epoch 5/5\n",
      "5001241/5001241 [==============================] - 212s 42us/step - loss: 85.2339 - val_loss: 67.6933\n"
     ]
    }
   ],
   "source": [
    "call_model.compile(optimizer=Adam(lr=1e-3), loss='mse')\n",
    "history = call_model.fit(call_X_train, call_y_train, \n",
    "                    batch_size=n_batch, epochs=5, \n",
    "                    validation_split = 0.01,\n",
    "                    callbacks=[TensorBoard()],\n",
    "                    verbose=1)\n",
    "call_model.save('saved-models/20191207-call-lstm-v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5001241 samples, validate on 50518 samples\n",
      "Epoch 1/5\n",
      "5001241/5001241 [==============================] - 216s 43us/step - loss: 79.8076 - val_loss: 29.9342\n",
      "Epoch 2/5\n",
      "5001241/5001241 [==============================] - 211s 42us/step - loss: 79.8083 - val_loss: 30.1453\n",
      "Epoch 3/5\n",
      "5001241/5001241 [==============================] - 210s 42us/step - loss: 84.3016 - val_loss: 35.7384\n",
      "Epoch 4/5\n",
      "5001241/5001241 [==============================] - 211s 42us/step - loss: 81.2422 - val_loss: 30.2354\n",
      "Epoch 5/5\n",
      "5001241/5001241 [==============================] - 210s 42us/step - loss: 81.1828 - val_loss: 29.8206\n"
     ]
    }
   ],
   "source": [
    "call_model.compile(optimizer=Adam(lr=1e-4), loss='mse')\n",
    "history = call_model.fit(call_X_train, call_y_train, \n",
    "                    batch_size=n_batch, epochs=5, \n",
    "                    validation_split = 0.01,\n",
    "                    callbacks=[TensorBoard()],\n",
    "                    verbose=1)\n",
    "call_model.save('saved-models/20191207-call-lstm-v3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5535888 samples, validate on 55919 samples\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/10\n",
      "5535888/5535888 [==============================] - 241s 44us/step - loss: 575.4231 - val_loss: 79.2370\n",
      "Epoch 2/10\n",
      "5535888/5535888 [==============================] - 236s 43us/step - loss: 75.6283 - val_loss: 137.2582\n",
      "Epoch 3/10\n",
      "5535888/5535888 [==============================] - 236s 43us/step - loss: 72.5753 - val_loss: 71.2110\n",
      "Epoch 4/10\n",
      "5535888/5535888 [==============================] - 235s 43us/step - loss: 72.3062 - val_loss: 173.4462\n",
      "Epoch 5/10\n",
      "5535888/5535888 [==============================] - 236s 43us/step - loss: 65.8853 - val_loss: 135.3481\n",
      "Epoch 6/10\n",
      "5535888/5535888 [==============================] - 236s 43us/step - loss: 62.2962 - val_loss: 212.6045\n",
      "Epoch 7/10\n",
      "5535888/5535888 [==============================] - 237s 43us/step - loss: 61.3266 - val_loss: 88.6632\n",
      "Epoch 8/10\n",
      "5535888/5535888 [==============================] - 237s 43us/step - loss: 55.5996 - val_loss: 66.6041\n",
      "Epoch 9/10\n",
      "5535888/5535888 [==============================] - 236s 43us/step - loss: 55.2409 - val_loss: 115.7667\n",
      "Epoch 10/10\n",
      "5535888/5535888 [==============================] - 237s 43us/step - loss: 52.5142 - val_loss: 46.6884\n"
     ]
    }
   ],
   "source": [
    "put_model.compile(optimizer=Adam(lr=1e-2), loss='mse')\n",
    "history = put_model.fit(put_X_train, put_y_train, \n",
    "                    batch_size=n_batch, epochs=10, \n",
    "                    validation_split = 0.01,\n",
    "                    callbacks=[TensorBoard()],\n",
    "                    verbose=1)\n",
    "put_model.save('saved-models/20191207-put-lstm-v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5535888 samples, validate on 55919 samples\n",
      "Epoch 1/5\n",
      "5535888/5535888 [==============================] - 244s 44us/step - loss: 42.0835 - val_loss: 27.3563\n",
      "Epoch 2/5\n",
      "5535888/5535888 [==============================] - 238s 43us/step - loss: 41.1786 - val_loss: 29.0307\n",
      "Epoch 3/5\n",
      "5535888/5535888 [==============================] - 238s 43us/step - loss: 40.0425 - val_loss: 38.7083\n",
      "Epoch 4/5\n",
      "5535888/5535888 [==============================] - 238s 43us/step - loss: 39.4841 - val_loss: 25.4669\n",
      "Epoch 5/5\n",
      "5535888/5535888 [==============================] - 238s 43us/step - loss: 38.4308 - val_loss: 38.1141\n"
     ]
    }
   ],
   "source": [
    "put_model.compile(optimizer=Adam(lr=1e-3), loss='mse')\n",
    "history = put_model.fit(put_X_train, put_y_train, \n",
    "                    batch_size=n_batch, epochs=5, \n",
    "                    validation_split = 0.01,\n",
    "                    callbacks=[TensorBoard()],\n",
    "                    verbose=1)\n",
    "put_model.save('saved-models/20191207-put-lstm-v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5535888 samples, validate on 55919 samples\n",
      "Epoch 1/5\n",
      "5535888/5535888 [==============================] - 246s 44us/step - loss: 37.2347 - val_loss: 23.1828\n",
      "Epoch 2/5\n",
      "5535888/5535888 [==============================] - 239s 43us/step - loss: 37.4697 - val_loss: 23.0973\n",
      "Epoch 3/5\n",
      "5535888/5535888 [==============================] - 239s 43us/step - loss: 36.9799 - val_loss: 23.0836\n",
      "Epoch 4/5\n",
      "5535888/5535888 [==============================] - 239s 43us/step - loss: 36.4919 - val_loss: 23.2828\n",
      "Epoch 5/5\n",
      "5535888/5535888 [==============================] - 239s 43us/step - loss: 36.8620 - val_loss: 22.8842\n"
     ]
    }
   ],
   "source": [
    "put_model.compile(optimizer=Adam(lr=1e-4), loss='mse')\n",
    "history = put_model.fit(put_X_train, put_y_train, \n",
    "                    batch_size=n_batch, epochs=5, \n",
    "                    validation_split = 0.01,\n",
    "                    callbacks=[TensorBoard()],\n",
    "                    verbose=1)\n",
    "put_model.save('saved-models/20191207-put-lstm-v3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
